{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Airport Reliability Dashboard\n",
    "Filter & Fly has had problems with airports and airlines constantly being delayed or cancelled. This leads to frustrations with their customers who demand a refund for their trip. They have tasked us with creating a dashboard to identify airport and airline risks in order to reduce customer frustration and avoid rebooking/refund costs.\n",
    "\n",
    "## Key questions include:\n",
    "* Which airlines have the lowest likelihood of delay, and which airports are consistently most on-time?\n",
    "* How do delay rates and average delay minutes change by season or month?\n",
    "* What are the most common causes (carrier, weather, airport) for specific airline–airport combinations?\n",
    "* Correlation with airlines and airports?\n",
    "* Ranking reliability on the dashboard (low risk or high risk filters)?\n",
    "* Risk by state/location and by season?\n",
    "\n",
    "* Using these insights, the agency can recommend lower-risk routes, suggest better departure seasons, and flag high-risk itineraries that may need extra buffer time or backup options. To clarify, **we are not forecasting** but providing information to help the travel agency make informed business decisions."
   ],
   "id": "3933a5785a9b31d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:15:59.973245Z",
     "start_time": "2026-02-18T01:15:59.940005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats"
   ],
   "id": "185372ae354c8da4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading the Data\n",
    "* year: The calendar year of the recorded flight operations.\n",
    "* month: The month (1–12) corresponding to the data entry.\n",
    "* carrier: The airline’s IATA carrier code (e.g., “9E”).\n",
    "* carrier_name: Full official name of the airline (e.g., “Endeavor Air Inc.”).\n",
    "* airport: The IATA airport code of the origin airport (e.g., “ABE”).\n",
    "* airport_name: Full name of the origin airport, including city and state.\n",
    "* arr_flights: Total number of arrival flights operated in that month for the given airline–airport pair.\n",
    "* arr_del15: Number of arrival flights delayed by 15 minutes or more (DOT standard definition of a delay).\n",
    "* carrier_ct: Count of flights delayed due to airline-related issues (e.g., crew delays, maintenance, equipment problems).\n",
    "* weather_ct: Count of flights delayed because of significant weather conditions.\n",
    "* nas_ct: Count of flights delayed due to National Airspace System issues (e.g., air traffic control, heavy traffic volume, system capacity).\n",
    "* security_ct: Count of flights delayed due to security-related factors (e.g., screening issues, security breaches).\n",
    "* late_aircraft_ct: Count of flights delayed because the aircraft arrived late from a previous flight.\n",
    "* arr_cancelled: Number of flights that were cancelled in that month for the given airline–airport pair.\n",
    "* arr_diverted: Number of flights that were diverted to another airport in that month for the given airline–airport pair.\n",
    "* arr_delay: Total arrival delay minutes across all causes for that airline/airport/month.\n",
    "* carrier_delay: Total minutes of delay caused by carrier-related issues.\n",
    "* weather_delay: Total minutes of delay caused by weather.\n",
    "* nas_delay: Total minutes of delay caused by NAS/air-traffic system constraints.\n",
    "* security_delay: Total minutes of delay caused by security-related disruptions.\n",
    "* late_aircraft_delay: Total minutes of delay caused by late-arriving aircraft."
   ],
   "id": "cc62feb27ec8bee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:16:00.226759Z",
     "start_time": "2026-02-18T01:15:59.974105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delays_df = pd.read_csv(\"csv/Airline_Delay_Cause.csv\")\n",
    "delays_df.info()"
   ],
   "id": "b71cec16cbe6d9da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318017 entries, 0 to 318016\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   year                 318017 non-null  int64  \n",
      " 1   month                318017 non-null  int64  \n",
      " 2   carrier              318013 non-null  object \n",
      " 3   carrier_name         318013 non-null  object \n",
      " 4   airport              318014 non-null  object \n",
      " 5   airport_name         318017 non-null  object \n",
      " 6   arr_flights          317524 non-null  float64\n",
      " 7   arr_del15            317285 non-null  float64\n",
      " 8   carrier_ct           317525 non-null  float64\n",
      " 9   weather_ct           317523 non-null  float64\n",
      " 10  nas_ct               317529 non-null  float64\n",
      " 11  security_ct          317529 non-null  float64\n",
      " 12  late_aircraft_ct     317529 non-null  float64\n",
      " 13  arr_cancelled        317529 non-null  float64\n",
      " 14  arr_diverted         317527 non-null  float64\n",
      " 15  arr_delay            317523 non-null  float64\n",
      " 16  carrier_delay        317525 non-null  float64\n",
      " 17  weather_delay        317529 non-null  float64\n",
      " 18  nas_delay            317529 non-null  float64\n",
      " 19  security_delay       317527 non-null  float64\n",
      " 20  late_aircraft_delay  317529 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(4)\n",
      "memory usage: 51.0+ MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "I will be dropping most NULL rows within the arr_flights column. This column represents the total number of arrival flights for that particular airport-airline pair, and the NULL values represent 0 flights given that pairing. However for the rows with data in the following columns, I will be keeping those rows and transforming the arr_flights value to 0."
   ],
   "id": "d6bd360619baa090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:16:00.259748Z",
     "start_time": "2026-02-18T01:16:00.227975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# checking for NULL flight counts\n",
    "delays_df[delays_df['arr_flights'].isna()].info()\n",
    "\n",
    "# handling NULL flights, but preserving the flights with valid cancellation, diverted, and delay information\n",
    "delays_df = delays_df.dropna(\n",
    "    subset=['arr_flights', 'arr_del15', 'arr_cancelled', 'arr_diverted'],\n",
    "    how='all'\n",
    ")\n",
    "# any preserved flights will still have a 0 flight count\n",
    "delays_df['arr_flights'] = delays_df['arr_flights'].fillna(0)"
   ],
   "id": "d4d823fe7ae42340",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 493 entries, 2872 to 316944\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   year                 493 non-null    int64  \n",
      " 1   month                493 non-null    int64  \n",
      " 2   carrier              493 non-null    object \n",
      " 3   carrier_name         493 non-null    object \n",
      " 4   airport              493 non-null    object \n",
      " 5   airport_name         493 non-null    object \n",
      " 6   arr_flights          0 non-null      float64\n",
      " 7   arr_del15            5 non-null      float64\n",
      " 8   carrier_ct           5 non-null      float64\n",
      " 9   weather_ct           5 non-null      float64\n",
      " 10  nas_ct               5 non-null      float64\n",
      " 11  security_ct          5 non-null      float64\n",
      " 12  late_aircraft_ct     5 non-null      float64\n",
      " 13  arr_cancelled        5 non-null      float64\n",
      " 14  arr_diverted         5 non-null      float64\n",
      " 15  arr_delay            5 non-null      float64\n",
      " 16  carrier_delay        5 non-null      float64\n",
      " 17  weather_delay        5 non-null      float64\n",
      " 18  nas_delay            5 non-null      float64\n",
      " 19  security_delay       5 non-null      float64\n",
      " 20  late_aircraft_delay  5 non-null      float64\n",
      "dtypes: float64(15), int64(2), object(4)\n",
      "memory usage: 84.7+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I will be converting NULL arr_diverted columns to 0 because this represents the number of flights that were diverted to another airport in that month for the given airline–airport pair, which doesn't impact much else of my dataset.\n",
    "\n",
    "For the NULL delay columns, the variables add up to the arr_delay, so I handled the NULL values by setting the NULL variable columns (security_delay & carrier_delay) to 0 and then adding the values together to get the arr_delay. Same goes for the count columns and the arr_del15."
   ],
   "id": "9f3f4291fbd248d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:16:00.313564Z",
     "start_time": "2026-02-18T01:16:00.267806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# handling NULL diverted flights\n",
    "delays_df['arr_diverted'] = delays_df['arr_diverted'].fillna(0)\n",
    "\n",
    "# handling NULL delays\n",
    "delays_df['security_delay'] = delays_df['security_delay'].fillna(0)\n",
    "delays_df['carrier_delay'] = delays_df['carrier_delay'].fillna(0)\n",
    "delay_var = [\n",
    "    'carrier_delay',\n",
    "    'weather_delay',\n",
    "    'nas_delay',\n",
    "    'security_delay',\n",
    "    'late_aircraft_delay'\n",
    "]\n",
    "\n",
    "# filling in missing delay time with sum of all delay variables\n",
    "delays_df['arr_delay'] = delays_df['arr_delay'].fillna(delays_df[delay_var].sum(axis=1))\n",
    "\n",
    "# handling NULL counts\n",
    "delays_df['carrier_ct'] = delays_df['carrier_ct'].fillna(0)\n",
    "delays_df['weather_ct'] = delays_df['weather_ct'].fillna(0)\n",
    "count_var = [\n",
    "    'carrier_ct',\n",
    "    'weather_ct',\n",
    "    'nas_ct',\n",
    "    'security_ct',\n",
    "    'late_aircraft_ct',\n",
    "]\n",
    "\n",
    "# filling in missing delay counts with sum of all count variables\n",
    "delays_df['arr_del15'] = delays_df['arr_del15'].fillna(delays_df[count_var].sum(axis=1))"
   ],
   "id": "9576de4d45690ad7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As for the string value columns, the rows with a missing carrier were deemed to me as useless, so I decided to drop them if they had neither a carrier or carrier_name.\n",
    "\n",
    "The missing airport values were a bit trickier since they had an airport_name, but a missing airport code. So I had to build a map of the groups for the missing values to be correctly filled in with their proper airport codes."
   ],
   "id": "baff6bb882ab2841"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:16:00.417071Z",
     "start_time": "2026-02-18T01:16:00.316953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# handling NULL carriers\n",
    "delays_df = delays_df.dropna(\n",
    "    subset=['carrier', 'carrier_name'],\n",
    "    how='all'\n",
    ")\n",
    "\n",
    "# handling missing airport cells\n",
    "missing_airport_codes = delays_df.loc[delays_df['airport'].isna(), 'airport_name']\n",
    "\n",
    "# creating a map of all unique airports and their airport codes\n",
    "airport_groups = (\n",
    "    delays_df\n",
    "    .dropna(subset=['airport', 'airport_name'])\n",
    "    .groupby('airport_name')['airport']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# filling blank airport cells from the airport groups map\n",
    "delays_df['airport'] = delays_df['airport'].fillna(\n",
    "    delays_df['airport_name'].map(airport_groups)\n",
    ")"
   ],
   "id": "f6ef9f8f454bdd4a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From this data cleaning, we've lost about 492 rows of data, but given that there were proper cleaning procedures performed on the dataset, it can be considered a necessary loss.\n",
    "\n",
    "For the sake of easy data analysis, I will be adding 3 new columns that are made up of the airport_name column, including city, state, and the airport_name_cleansed. This essentially makes it easier to parse information rather than pulling from a single, concatenated string. I also rename airport to airport_code and airport_name to airport_full_name for clarity."
   ],
   "id": "9e19f69159785b76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T01:17:36.114080Z",
     "start_time": "2026-02-18T01:17:33.895410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# splitting the string by punctuation (identified pattern in the airport_name column)\n",
    "airport_names = delays_df['airport_name'].str.split(\",|:\", expand=True)\n",
    "airport_names.columns = ['city', 'state', 'airport_name_cleansed']\n",
    "\n",
    "# inserting columns into main dataframe, after airport codes\n",
    "delays_df.insert(5, \"city\", airport_names['city'].str.strip())\n",
    "delays_df.insert(6, \"state\", airport_names['state'].str.strip())\n",
    "delays_df.insert(8, \"airport_name_cleansed\", airport_names['airport_name_cleansed'].str.strip())\n",
    "\n",
    "# renaming airport to airport_code and airport_name to airport_full_name for clarity\n",
    "delays_df = delays_df.rename(columns = {\"airport\": \"airport_code\", \"airport_name\": \"airport_full_name\"})\n",
    "delays_df[\"airport_code\"] = delays_df[\"airport_code\"].astype(str)\n",
    "\n",
    "# converting year and month into datetime type\n",
    "delays_df.insert(0, \"year_month\", pd.to_datetime(delays_df['year'].astype(str) + '-' + delays_df['month'].astype(str) + '-01'))\n",
    "\n",
    "# saving cleaned dataframe into new csv file\n",
    "delays_df.to_csv('./csv/delays_transformed.csv', index=False, encoding='utf-8')\n",
    "delays_df.info()"
   ],
   "id": "2fe79ce0423bf50f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 317525 entries, 0 to 318016\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   year_month             317525 non-null  datetime64[ns]\n",
      " 1   year                   317525 non-null  int64         \n",
      " 2   month                  317525 non-null  int64         \n",
      " 3   carrier                317525 non-null  object        \n",
      " 4   carrier_name           317525 non-null  object        \n",
      " 5   airport_code           317525 non-null  object        \n",
      " 6   city                   317525 non-null  object        \n",
      " 7   state                  317525 non-null  object        \n",
      " 8   airport_full_name      317525 non-null  object        \n",
      " 9   airport_name_cleansed  317525 non-null  object        \n",
      " 10  arr_flights            317525 non-null  float64       \n",
      " 11  arr_del15              317525 non-null  float64       \n",
      " 12  carrier_ct             317525 non-null  float64       \n",
      " 13  weather_ct             317525 non-null  float64       \n",
      " 14  nas_ct                 317525 non-null  float64       \n",
      " 15  security_ct            317525 non-null  float64       \n",
      " 16  late_aircraft_ct       317525 non-null  float64       \n",
      " 17  arr_cancelled          317525 non-null  float64       \n",
      " 18  arr_diverted           317525 non-null  float64       \n",
      " 19  arr_delay              317525 non-null  float64       \n",
      " 20  carrier_delay          317525 non-null  float64       \n",
      " 21  weather_delay          317525 non-null  float64       \n",
      " 22  nas_delay              317525 non-null  float64       \n",
      " 23  security_delay         317525 non-null  float64       \n",
      " 24  late_aircraft_delay    317525 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(15), int64(2), object(7)\n",
      "memory usage: 63.0+ MB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Visualizations Figure 1: Number of Cancellations by Carrier\n",
    "For this visualization, I am looking at the correlation of carrier and their cancellation rates for a specified year. For the simplicity of this line graph, I chose the most cancelled airport within a specified year, which can be changed if needed. Then I made a subset of the main dataframe only containing the airport during the specific year, the months, and the number of cancellations per carrier within each month. This is useful to analyze the reliability of various carriers, within a specific airport and to see the trends as the number of cancellations vary by each month."
   ],
   "id": "19aeb1e9a065ac29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# which airport has the most cancelled flights\n",
    "year_to_analyze = 2017\n",
    "most_cancelled_airport = delays_df.loc[delays_df['year'] == year_to_analyze].groupby('airport_code')['arr_cancelled'].sum().idxmax()\n",
    "\n",
    "# subset of main dataframe\n",
    "carrier_cancellation_df = delays_df[\n",
    "    (delays_df[\"airport_code\"] == most_cancelled_airport) &\n",
    "        (delays_df['year'] == year_to_analyze)\n",
    "][[\"month\", \"arr_cancelled\", \"carrier_name\"]]\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.lineplot(\n",
    "    data=carrier_cancellation_df,\n",
    "    x='month',\n",
    "    y='arr_cancelled',\n",
    "    hue='carrier_name'\n",
    ")\n",
    "\n",
    "plt.title(f\"Cancellations by Carrier at {most_cancelled_airport} in {year_to_analyze}\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"# of Cancelled Flights\")\n",
    "plt.xticks(range(1,13))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9db901b45acb5181",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Visualizations Figure 2: On-Time Trends by Carrier\n",
    "For this visualization, I am looking at the relationship between carriers and the number of on-time versus delayed flights for a specified year. For simplicity, I chose the airport with the highest number of flights within that year, which can be changed if needed. I then created a subset of the main dataframe that only includes flights from the selected airport during the specified year and combined the number of on-time flights and different types of delays, sorted by carrier. This is useful for comparing carrier reliability at a single, high-traffic airport and for observing how various delay types contribute to overall flight disruptions across carriers.\n"
   ],
   "id": "639454e5a0c5f694"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year_to_analyze = 2021\n",
    "airport_most_flights = delays_df.loc[delays_df['year'] == year_to_analyze].groupby('airport_code')['arr_flights'].sum().idxmax()\n",
    "no_delays_df = (delays_df[\n",
    "        (delays_df[\"airport_code\"] == airport_most_flights) &\n",
    "    (delays_df[\"year\"] == year_to_analyze)\n",
    "].groupby(\"carrier_name\", as_index=False)[[\"arr_flights\", 'arr_del15', 'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay']].sum())\n",
    "\n",
    "# renaming column names for clarity\n",
    "no_delays_df = no_delays_df.rename(columns={'carrier_delay': 'Carrier Delay', 'weather_delay': 'Weather Delay', 'nas_delay': 'NAS Delay', 'security_delay': 'Security Delay', 'late_aircraft_delay': 'Late Aircraft Delay'})\n",
    "no_delays_df.insert(1, 'On-Time Flights', no_delays_df['arr_flights'] - no_delays_df['arr_del15'])\n",
    "no_delays_df.drop(columns=['arr_flights', 'arr_del15'], inplace=True)\n",
    "print(no_delays_df.head())\n",
    "\n",
    "no_delays_df.set_index('carrier_name').plot(kind='bar', stacked=True, figsize=(12,9))\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title(f'Delay vs. On-Time by Carrier at {airport_most_flights} in {year_to_analyze}')\n",
    "plt.xlabel('Carrier')\n",
    "plt.ylabel('Number of Flights')\n",
    "plt.show()"
   ],
   "id": "233c597bd53e5a3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Visualization Figure 3: Weather Delays at an Airport Split by Carrier\n",
    "For this visualization, I am looking at the distribution of weather-related delays across carriers for a specified month and year. For simplicity, I selected the airport with the highest total number of weather delays within the specified year, which can be changed if needed. I then created a subset of the main dataframe that only includes flights from the selected airport during the specified month and year, along with the associated carriers and their weather delay counts. This visualization is useful for understanding how weather-related delays are distributed among carriers at a high-impact airport and for identifying which carriers contribute most to weather delays during a specific time period."
   ],
   "id": "fbf6ab01aa029dc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year_to_analyze = 2015\n",
    "month_to_analyze = 10\n",
    "airport_most_weather_delays = delays_df.loc[delays_df['year'] == year_to_analyze].groupby('airport_code')['weather_delay'].sum().idxmax()\n",
    "\n",
    "weather_delays_df = delays_df[\n",
    "    (delays_df[\"airport_code\"] == airport_most_weather_delays) &\n",
    "    (delays_df[\"year\"] == year_to_analyze) &\n",
    "    (delays_df[\"month\"] == month_to_analyze)\n",
    "][[\"weather_delay\", \"carrier_name\"]]\n",
    "\n",
    "total_weather_delays = weather_delays_df['weather_delay'].sum().astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pie(weather_delays_df['weather_delay'], labels=weather_delays_df['carrier_name'])\n",
    "plt.title(f'Weather Delays by Carrier at {airport_most_weather_delays} in {month_to_analyze}/{year_to_analyze} (Total Flights Delayed: {total_weather_delays})', loc='center')\n",
    "plt.show()"
   ],
   "id": "37ac5f7b0d12234d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Visualization Figure 4: Delay for Specific Carrier\n",
    "For this visualization, I am looking at how different types of delays for a specific carrier change across the months of a year at a selected airport. I created a subset of the data for Delta, at SeaTac, and in 2017 as an example, summing the delays by type for each month. This helps show seasonal patterns and which delays are most common at different times of the year."
   ],
   "id": "40c197b59c7217f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year_to_analyze = 2017\n",
    "carrier_to_analyze = 'Delta Air Lines'\n",
    "airport_to_analyze = 'SEA'\n",
    "\n",
    "monthly_delays_df = delays_df[\n",
    "    (delays_df['year'] == year_to_analyze) &\n",
    "    (delays_df['carrier_name'].str.contains(carrier_to_analyze)) &\n",
    "    (delays_df['airport_code'] == airport_to_analyze)\n",
    "].groupby('month')[['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay']].sum().reset_index()\n",
    "monthly_delays_df = monthly_delays_df.rename(columns={'carrier_delay': 'Carrier Delay', 'weather_delay': 'Weather Delay', 'nas_delay': 'NAS Delay', 'security_delay': 'Security Delay', 'late_aircraft_delay': 'Late Aircraft Delay'})\n",
    "\n",
    "monthly_delays_df.plot(\n",
    "    x='month',\n",
    "    kind='line',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title(f'Delays for {carrier_to_analyze} in {airport_to_analyze} ({year_to_analyze})')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Delays')\n",
    "plt.xticks(range(1,13))\n",
    "plt.show()"
   ],
   "id": "c887584c26374f5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Findings\n",
    "### Next Steps:\n",
    "From the EDA, the team should focus on which carriers and airports have the most delays, the types of delays, and how they change over months. The next step is turning these insights into clear metrics and visualizations for stakeholders. Turning the quantified metrics into descriptive qualities to describe each carrier would help our stakeholder make informative decisions, which would be ideal.\n",
    "### Dataset:\n",
    "I think the dataset is sufficient enough to answer the stakeholder questions, but finding flight origins or months with unusual happenings, like government shutdowns or massive historical events, could be interesting to dive into if we wanted to explore more about the reasoning behind airline delays/cancellations.\n",
    "### Data Mining & Patterns:\n",
    "I saw that in weather delays visualization, even when changing the month, there is a carrier who makes the majority of these delays. While we don't necessarily know if these delays are caused by weather in the destination or the origin location, it might be worth diving into.\n",
    "\n",
    "Also, in the general breakdown of various delay causes in visualization figure 2, there's a large amount of flights with Delta, but it might be worth breaking these statistics down into percentages and seeing if there's a pattern of the various delay types.\n",
    "\n",
    "In November 2018 of Figure 1, there is a cancellation hike in the visualization that might be worth exploring. While not all of the carriers experience this rise in cancellations, it's a good amount of data to show a correlation.\n",
    "### Story & Dashboard:\n",
    "The story is about flight reliability, which carriers and airports perform well, which delays matter most, and when.\n",
    "Some dashboard ideas that would be definitely beneficial to communicating information would be stacked/grouped bars for delay types by carrier, line charts for monthly trends, pie charts for delay distribution, correlations in delays for airports and carriers. It would also be worth adding KPIs like on-time %, total delays, and average delays per carrier.\n",
    "### Knowns & Unknowns:\n",
    "There were some rows with data but missing carrier names and I'm wondering if these were independent carriers or something else. I do know that I dropped rows with 0 flights between airlines and airports to clean the data, so I also wonder if the reasons behind these lack of flights is due to a partnership being broken off or otherwise.\n",
    "### Reflection:\n",
    "Doing this EDA gave me a good understanding of the dataset and trends. I feel more confident knowing which metrics to track and how to work with the team on the dashboard. I think being immersed in the data is an easy way of understanding the data on a deep level and will assist in being able to explain and assist my teammates with this project effectively."
   ],
   "id": "d92c4035f15c72f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
